{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/CombinedTrust0_3', '/CombinedTrust1_3', '/CombinedTrust2_3']\n"
     ]
    }
   ],
   "source": [
    "from bounos.Analyses import Weight\n",
    "import operator\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "_ = np.seterr(invalid='ignore') # Pandas PITA Nan printing\n",
    "\n",
    "import bounos.ChartBuilders as cb\n",
    "import bounos.Analyses.Trust as Trust\n",
    "\n",
    "import os\n",
    "\n",
    "def map_level(df, dct, level=0):\n",
    "    index = df.index\n",
    "    index.set_levels([[dct.get(item, item) for item in names] if i==level else names\n",
    "                      for i, names in enumerate(index.levels)], inplace=True)\n",
    "\n",
    "\n",
    "cb.latexify(columns=0.5, factor=1)\n",
    "\n",
    "phys_keys = ['INDD','INHD','Speed']\n",
    "comm_keys = ['ADelay','ARXP','ATXP','RXThroughput','TXThroughput','PLR']\n",
    "observer = 'Bravo'\n",
    "target = 'Alfa'\n",
    "n_nodes = 6\n",
    "n_metrics = 9\n",
    "par=False\n",
    "\n",
    "results_path = \"/home/bolster/src/aietes/results/Malicious Behaviour Trust Comparison-2015-07-20-17-47-53\"\n",
    "\n",
    "fig_basedir = \"/home/bolster/src/thesis/papers/active/16_AAMAS/img\"\n",
    "\n",
    "\n",
    "var_rename_dict = {'CombinedBadMouthingPowerControl':'MPC',\n",
    " 'CombinedSelfishTargetSelection':'STS',\n",
    " 'CombinedTrust':'Fair',\n",
    " 'Shadow':'Shadow',\n",
    " 'SlowCoach':'SlowCoach'}\n",
    "\n",
    "metric_rename_dict = {\n",
    "    'ADelay': \"$Delay$\",\n",
    "    'ARXP': \"$P_{RX}$\",\n",
    "    'ATXP': \"$P_{TX}$\",\n",
    "    'RXThroughput': \"$T^P_{RX}$\",\n",
    "    'TXThroughput': \"$T^P_{TX}$\",\n",
    "    'PLR': '$PLR$',\n",
    "    'INDD': '$INDD$',\n",
    "    'INHD': '$INHD$',\n",
    "    'Speed': '$Speed$'\n",
    "}\n",
    "inv_map = lambda d: {v: k for k, v in d.items()}\n",
    "\n",
    "results_path = \"/home/bolster/src/aietes/results/Malicious Behaviour Trust Comparison-2015-07-20-17-47-53\"\n",
    "with pd.get_store(results_path + \"/outliers.bkup.h5\") as store:\n",
    "    print store.keys()\n",
    "    weight_df = store.get(store.keys()[0])\n",
    "    keys  = list(weight_df.keys())\n",
    "    top_line = weight_df.values[0:100]\n",
    "    del weight_df\n",
    "    \n",
    "from scipy.sparse import csc_matrix\n",
    "def sparsify(a):\n",
    "    indices = np.nonzero(~np.isnan(a))\n",
    "    return csc_matrix((a[indices], indices), shape=a.shape, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range_index = keys.index('range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configs_k, nodes_k, metrics_k = np.split(keys, (5, 5+n_nodes))\n",
    "nodes_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configs, nodes, metrics = np.split(top_line, (5, 5+n_nodes), axis=1)\n",
    "nodes=nodes.astype(np.float)\n",
    "metrics=metrics.astype(np.float)\n",
    "nodes[configs[:,-1]=='lower'] = -nodes[configs[:,-1]=='lower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sparsify(nodes).toarray().sum(axis=1)==np.nansum(nodes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.get_store(results_path + '.h5') as store:\n",
    "    trust_observations = store.trust.xs('Bravo',level='observer', drop_level=False).dropna()\n",
    "    \n",
    "unweighted_trust_perspectives = Trust.generate_node_trust_perspective(trust_observations,\n",
    "                                                                    metric_weights=None,\n",
    "                                                                    par=False)\n",
    "map_level(unweighted_trust_perspectives, var_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_outlier_tp(tf, sigma=None, good='good', good_lvl='bev'):\n",
    "    \"\"\"\n",
    "    This must be applied on a per-observation basis (i.e. single run, single observer)\n",
    "    :param tf:\n",
    "    :param sigma:\n",
    "    :param good:\n",
    "    :param good_lvl:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if sigma is not None:\n",
    "        raise NotImplementedError(\"!Have't implemented\")\n",
    "\n",
    "    _mean=tf.xs(good,level=good_lvl).mean()\n",
    "    _std=tf.xs(good,level=good_lvl).std()\n",
    "    llim=_mean-_std\n",
    "    ulim=_mean+_std\n",
    "    uppers = (tf[tf>ulim]-ulim).reset_index()\n",
    "    lowers = (llim-tf[tf<llim]).reset_index()\n",
    "    outliers = pd.concat((uppers,lowers), keys=('upper','lower'), names=['range','id']).reset_index().set_index(\n",
    "        ['var','run','observer','range','t']\n",
    "    )\n",
    "    outliers.drop('id', axis=1, inplace=True)\n",
    "    return outliers\n",
    "\n",
    "w = Weight.norm_weight(pd.Series(1,trust_observations.keys()))\n",
    "\n",
    "l_outliers = []\n",
    "for i, tf in unweighted_trust_perspectives.groupby(level=['run', 'observer']):\n",
    "    l_outliers.append(generate_outlier_tp(tf, good='Fair', good_lvl='var'))\n",
    "outlier = pd.concat(l_outliers).sort_index().dropna(how='all').reset_index()\n",
    "for k in w.keys():\n",
    "    outlier[k] = w[k]\n",
    "outlier.set_index(['var', 't'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "weight_df = pd.concat([outlier]).reset_index()\n",
    "\n",
    "observer = 'Bravo'\n",
    "target = 'Alfa'\n",
    "n_metrics = 9\n",
    "# Select Perspective here\n",
    "weight_df = weight_df[weight_df.observer == observer]\n",
    "#weight_df = categorise_dataframe(weight_df)\n",
    "\n",
    "# Metrics are the last sector of the frame, set these as leading indices\n",
    "metric_keys = list(weight_df.keys()[-n_metrics:])\n",
    "weight_df.set_index(metric_keys + ['var', 't'], inplace=True)\n",
    "\n",
    "# REMEMBER TO CHECK THIS WHEN DOING MULTIPLE RUNS (although technically it shouldn't matter....)\n",
    "weight_df.drop(['observer', 'run'], axis=1, inplace=True)\n",
    "\n",
    "# Sum for each run (i.e. group by everything but time)\n",
    "time_summed_weights = weight_df.groupby(level=list(weight_df.index.names[:-1])).sum().unstack('var')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "d = {'upper':1, 'lower':-1}\n",
    "r = weight_df['range'].apply(d.get)\n",
    "f = lambda c: c*r\n",
    "x=weight_df.drop('range', axis=1).apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.groupby(level=list(weight_df.index.names[:-1])).sum().unstack('var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "time_summed_signs = weight_df.apply(lambda v: -v[1:] if v[0][0]=='l' else v[1:], axis=1).groupby(level=list(weight_df.index.names[:-1])).sum().unstack('var')\n",
    "time_summed_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Sum for each run (i.e. group by everything but time)\n",
    "time_summed_weights = weight_df.groupby(level=list(weight_df.index.names[:-1])).sum().unstack('var')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = {'key':'val'}\n",
    "\n",
    "def printer(**kwargs):\n",
    "    print kwargs \n",
    "test.update({'another':'val'})\n",
    "printer(**test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
